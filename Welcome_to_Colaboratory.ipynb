{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukkychan/scaling_to_high/blob/main/Welcome_to_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir original_video\n",
        "!mkdir org_no_sound\n",
        "!mkdir -p frames/1080p\n",
        "!mkdir -p frames/360p\n",
        "!mkdir scaled"
      ],
      "metadata": {
        "id": "b9snVJi30Ge1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the videos"
      ],
      "metadata": {
        "id": "vMeI6f4UxaYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://rr3---sn-i5h7lnll.googlevideo.com/videoplayback?expire=1687873118&ei=_pGaZK_yFZuWx_AP9c2bgAk&ip=194.163.187.202&id=o-ABQoFFKI-0TYpItnbUBExAW_WFhBuG8nGHo1l4CFhAvB&itag=18&source=youtube&requiressl=yes&mh=5x&mm=31%2C26&mn=sn-i5h7lnll%2Csn-5hne6n6l&ms=au%2Conr&mv=m&mvi=3&pl=24&initcwndbps=591250&spc=qEK7BzQe1PdnWmhw8X7fm6G_bDBY6vk&vprv=1&svpuc=1&mime=video%2Fmp4&gir=yes&clen=7096879&ratebypass=yes&dur=124.435&lmt=1687436485346821&mt=1687851193&fvip=5&fexp=24007246&c=ANDROID&txp=6319224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AOq0QJ8wRAIgLi21odpgQulN_4_GdFEVFpyniuUl6h2NNK50TfYENhgCIBr5HRx5w7eChj4_mdEOZuKebqN-POQwmCYhW85TJNWc&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRgIhAJi6bx2nbfyG0lLVEz5H7xOzg6wBfbf88AGS1mgfisRgAiEA8vRCYhGDORRcsZbcL4glRFkSgTxTBoVgbHCzDq2qNR0%3D&title=SPY%20Trailer%20(Telugu)%20|%20Nikhil%20Siddharth%20|%20Garry%20BH%20|%20Charantej%20Uppalapati%20|%20Ishwarya%20Menon\""
      ],
      "metadata": {
        "id": "z3FW3-UDxYSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the audios"
      ],
      "metadata": {
        "id": "xJVOytvJy301"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "ZZnAZuLUy_kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def remove_audio(input_video_path, output_video_path):\n",
        "    # Load the video clip\n",
        "    video = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Remove the audio\n",
        "    video_without_audio = video.without_audio()\n",
        "\n",
        "    # Save the video without audio\n",
        "    video_without_audio.write_videofile(output_video_path, codec='libx264')\n",
        "\n",
        "    # Close the video clip\n",
        "    video.close()\n",
        "\n",
        "# Specify the paths to the input video and desired output video\n",
        "input_video_path = '/content/original_video/360p.mp4'\n",
        "output_video_path = '/content/org_no_sound/360p.mp4'\n",
        "\n",
        "# Call the function to remove audio\n",
        "remove_audio(input_video_path, output_video_path)\n",
        "print(\"done.\")\n"
      ],
      "metadata": {
        "id": "RVdzq5Mmy6u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Frames"
      ],
      "metadata": {
        "id": "wwotNercz_mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the video file\n",
        "video_path = \"/content/org_no_sound/360p.mp4\"\n",
        "\n",
        "# Specify the output folder to save the frames\n",
        "output_folder = \"/content/frames/360p/\"\n",
        "\n",
        "# Specify the maximum number of frames to extract\n",
        "max_frames = 150\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the frame interval to evenly sample the frames\n",
        "frame_interval = max(total_frames // max_frames, 1)\n",
        "\n",
        "# Initialize a counter to keep track of the extracted frames\n",
        "frame_count = 0\n",
        "\n",
        "# Loop through the frames and extract the desired number of frames\n",
        "while frame_count < max_frames:\n",
        "    # Read the current frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image file\n",
        "    frame_path = f\"{output_folder}{frame_count:03d}.jpg\"\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    # Increment the frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Move to the next frame based on the frame interval\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "biGN7KYh0DND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the images to 1080p"
      ],
      "metadata": {
        "id": "teV6as_L3czN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def scale_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all image files in the input folder\n",
        "    image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Construct the input and output file paths\n",
        "        input_path = os.path.join(input_folder, image_file)\n",
        "        output_path = os.path.join(output_folder, image_file)\n",
        "\n",
        "        # Execute FFmpeg command to scale the image to 1920x1080\n",
        "        command = ['ffmpeg', '-i', input_path, '-vf', 'scale=1920:1080', output_path]\n",
        "        subprocess.call(command)\n",
        "\n",
        "# Specify the paths to the input folder and output folder\n",
        "input_folder = '/content/frames/360p/'\n",
        "output_folder = '/content/scaled/'\n",
        "\n",
        "# Call the function to scale the images\n",
        "scale_images(input_folder, output_folder)\n",
        "print(\"scaling done.\")\n"
      ],
      "metadata": {
        "id": "GFatlVKr3cSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "QvfUC2Vq4F0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "# Step 1: Organize data and directories\n",
        "original_dir = '/content/frames/1080p/'  # Directory containing original 1080p images\n",
        "scaled_dir = '/content/scaled/'  # Directory containing scaled images\n",
        "\n",
        "# Step 2: Load and preprocess the images\n",
        "original_images = []\n",
        "scaled_images = []\n",
        "\n",
        "for filename in os.listdir(original_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "        original_path = os.path.join(original_dir, filename)\n",
        "        scaled_path = os.path.join(scaled_dir, filename)\n",
        "\n",
        "        original_image = cv2.imread(original_path)\n",
        "        scaled_image = cv2.imread(scaled_path)\n",
        "\n",
        "        # Preprocess the images (resize and normalize)\n",
        "        original_image = cv2.resize(original_image, (256, 256)) / 255.0\n",
        "        scaled_image = cv2.resize(scaled_image, (256, 256)) / 255.0\n",
        "\n",
        "        original_images.append(original_image)\n",
        "        scaled_images.append(scaled_image)\n",
        "\n",
        "original_images = np.array(original_images)\n",
        "scaled_images = np.array(scaled_images)\n",
        "\n",
        "# Step 3: Define the U-Net model architecture\n",
        "inputs = Input(shape=(256, 256, 3))\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "\n",
        "up5 = Conv2D(256, 2, activation='relu', padding='same')(up5)\n",
        "merge5 = concatenate([conv3, up5], axis=3)\n",
        "conv5 = Conv2D(256, 3, activation='relu', padding='same')(merge5)\n",
        "conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
        "up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "\n",
        "up6 = Conv2D(128, 2, activation='relu', padding='same')(up6)\n",
        "merge6 = concatenate([conv2, up6], axis=3)\n",
        "conv6 = Conv2D(128, 3, activation='relu', padding='same')(merge6)\n",
        "conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
        "up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "\n",
        "up7 = Conv2D(64, 2, activation='relu', padding='same')(up7)\n",
        "merge7 = concatenate([conv1, up7], axis=3)\n",
        "conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
        "conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "output = Conv2D(3, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Step 4: Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(scaled_images, original_images, batch_size=32, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Step 5: Save the trained model\n",
        "model.save('/content/model.h5')\n",
        "\n",
        "# Step 6: Evaluate the model (optional)\n",
        "# test_images = [...]  # Load test images\n",
        "# predicted_images = model.predict(test_images)\n",
        "\n",
        "# Step 7: Inference on new scaled images (optional)\n",
        "# new_scaled_image = cv2.imread('path/to/new/scaled/image.jpg')\n",
        "# new_scaled_image = cv2.resize(new_scaled_image, (256, 256)) / 255.0\n",
        "# predicted_image = model.predict(np.array([new_scaled_image]))\n",
        "# predicted_image = predicted_image[0] * 255.0\n",
        "# cv2.imwrite('path/to/save/predicted/image.jpg', predicted_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mak56DIk4Cjs",
        "outputId": "b10efb8d-177e-40e7-f15f-4287345f14e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 730s 180s/step - loss: 0.1742 - val_loss: 0.1662\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 751s 191s/step - loss: 0.1138 - val_loss: 0.0651\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 719s 180s/step - loss: 0.0542 - val_loss: 0.0651\n",
            "Epoch 4/10\n",
            "3/4 [=====================>........] - ETA: 2:57 - loss: 0.0548"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}