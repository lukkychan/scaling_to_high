{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukkychan/scaling_to_high/blob/main/Welcome_to_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir original_video\n",
        "!mkdir org_no_sound\n",
        "!mkdir -p frames/1080p\n",
        "!mkdir -p frames/360p\n",
        "!mkdir scaled\n",
        "!mkdir predicted\n",
        "!mkdir Pre_orginal\n",
        "!mkdir dataset\n",
        "!mkdir -p dataset/1080p\n",
        "!mkdir -p dataset/360s"
      ],
      "metadata": {
        "id": "b9snVJi30Ge1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=eDTEiIC0_rE&pp=ygUSc3B5IHRyYWlsZXIgdGVsdWd1"
      ],
      "metadata": {
        "id": "oSal6RfTJJ8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the videos"
      ],
      "metadata": {
        "id": "vMeI6f4UxaYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"1080p.mp4\" \"https://cdn5.savetube.me/media/eDTEiIC0_rE/spy-trailer-telugu-nikhil-siddharth-garry-bh-charantej-uppalapati-ishwarya-menon-1080-ytshorts.savetube.me.mp4\""
      ],
      "metadata": {
        "id": "z3FW3-UDxYSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udU54MjMnheu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"360p.mp4\" \"https://rr1---sn-gxuo03g-3c2l.googlevideo.com/videoplayback?expire=1687952630&ei=lsibZK2rNovdyAXa3b2wBA&ip=176.123.9.161&id=o-AMxEECX-LkU2VPp4V3zzNwYxQhp2sfa8ng5QdUfXeKul&itag=18&source=youtube&requiressl=yes&mh=5x&mm=31%2C29&mn=sn-gxuo03g-3c2l%2Csn-4g5edndr&ms=au%2Crdu&mv=m&mvi=1&pcm2cms=yes&pl=25&spc=qEK7B5y533je3mDHkY3DHbCZB3VtmNw&vprv=1&svpuc=1&mime=video%2Fmp4&gir=yes&clen=7096879&ratebypass=yes&dur=124.435&lmt=1687436485346821&mt=1687930634&fvip=1&fexp=24007246%2C51000023&c=ANDROID&txp=6319224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AOq0QJ8wRQIgL94AHq0hK_IVxyifGh9LgZvuUDxGTQufQkDypHtYcpkCIQDUQbbO7lELHpc-wicZXPNY8G182HWUCQLbf5sRaGA6zw%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpcm2cms%2Cpl&lsig=AG3C_xAwRQIhAPtpgo-kgAt2lMMEZhplNCciZblGOiU_1Co1w2kCTRkiAiAx1VTs5wCCxJvBLLad6pdJeCvhZ9E3pZ87L2nw-AtT7g%3D%3D&title=SPY%20Trailer%20(Telugu)%20|%20Nikhil%20Siddharth%20|%20Garry%20BH%20|%20Charantej%20Uppalapati%20|%20Ishwarya%20Menon\""
      ],
      "metadata": {
        "id": "HJTW1xy5nhx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"1080p.mp4\" \"/content/original_video/\"\n",
        "!mv \"360p.mp4\" \"/content/original_video/\""
      ],
      "metadata": {
        "id": "veSDYI8cnsVO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the audios"
      ],
      "metadata": {
        "id": "xJVOytvJy301"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "ZZnAZuLUy_kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def remove_audio(input_video_path, output_video_path):\n",
        "    # Load the video clip\n",
        "    video = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Remove the audio\n",
        "    video_without_audio = video.without_audio()\n",
        "\n",
        "    # Save the video without audio\n",
        "    video_without_audio.write_videofile(output_video_path, codec='libx264')\n",
        "\n",
        "    # Close the video clip\n",
        "    video.close()\n",
        "\n",
        "# Specify the paths to the input video and desired output video\n",
        "input_video_path = '/content/original_video/1080p.mp4'\n",
        "output_video_path = '/content/org_no_sound/1080p.mp4'\n",
        "\n",
        "# Call the function to remove audio\n",
        "remove_audio(input_video_path, output_video_path)\n",
        "print(\"done.\")\n"
      ],
      "metadata": {
        "id": "VeEXxSqcKAI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def remove_audio(input_video_path, output_video_path):\n",
        "    # Load the video clip\n",
        "    video = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Remove the audio\n",
        "    video_without_audio = video.without_audio()\n",
        "\n",
        "    # Save the video without audio\n",
        "    video_without_audio.write_videofile(output_video_path, codec='libx264')\n",
        "\n",
        "    # Close the video clip\n",
        "    video.close()\n",
        "\n",
        "# Specify the paths to the input video and desired output video\n",
        "input_video_path = '/content/original_video/360p.mp4'\n",
        "output_video_path = '/content/org_no_sound/360p.mp4'\n",
        "\n",
        "# Call the function to remove audio\n",
        "remove_audio(input_video_path, output_video_path)\n",
        "print(\"done.\")\n"
      ],
      "metadata": {
        "id": "RVdzq5Mmy6u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Frames"
      ],
      "metadata": {
        "id": "wwotNercz_mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the video file\n",
        "video_path = \"/content/org_no_sound/360p.mp4\"\n",
        "\n",
        "# Specify the output folder to save the frames\n",
        "output_folder = \"/content/frames/360p/\"\n",
        "\n",
        "# Specify the maximum number of frames to extract\n",
        "max_frames = 50\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the frame interval to evenly sample the frames\n",
        "frame_interval = max(total_frames // max_frames, 1)\n",
        "\n",
        "# Initialize a counter to keep track of the extracted frames\n",
        "frame_count = 0\n",
        "\n",
        "# Loop through the frames and extract the desired number of frames\n",
        "while frame_count < max_frames:\n",
        "    # Read the current frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image file\n",
        "    frame_path = f\"{output_folder}{frame_count:03d}.jpg\"\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    # Increment the frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Move to the next frame based on the frame interval\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "biGN7KYh0DND",
        "outputId": "d6cea903-606c-4bd8-c78b-14d8a9e5aa19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the video file\n",
        "video_path = \"/content/org_no_sound/1080p.mp4\"\n",
        "\n",
        "# Specify the output folder to save the frames\n",
        "output_folder = \"/content/frames/1080p/\"\n",
        "\n",
        "# Specify the maximum number of frames to extract\n",
        "max_frames = 50\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the frame interval to evenly sample the frames\n",
        "frame_interval = max(total_frames // max_frames, 1)\n",
        "\n",
        "# Initialize a counter to keep track of the extracted frames\n",
        "frame_count = 0\n",
        "\n",
        "# Loop through the frames and extract the desired number of frames\n",
        "while frame_count < max_frames:\n",
        "    # Read the current frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image file\n",
        "    frame_path = f\"{output_folder}{frame_count:03d}.jpg\"\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "\n",
        "    # Increment the frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Move to the next frame based on the frame interval\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "wxI4cUVpKIbd",
        "outputId": "addd266b-dfd7-4ae9-9e55-88bc9bb389ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the images to 1080p"
      ],
      "metadata": {
        "id": "teV6as_L3czN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def scale_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all image files in the input folder\n",
        "    image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Construct the input and output file paths\n",
        "        input_path = os.path.join(input_folder, image_file)\n",
        "        output_path = os.path.join(output_folder, image_file)\n",
        "\n",
        "        # Execute FFmpeg command to scale the image to 1920x1080\n",
        "        command = ['ffmpeg', '-i', input_path, '-vf', 'scale=1920:1080', output_path]\n",
        "        subprocess.call(command)\n",
        "\n",
        "# Specify the paths to the input folder and output folder\n",
        "input_folder = '/content/frames/360p/'\n",
        "output_folder = '/content/scaled/'\n",
        "\n",
        "# Call the function to scale the images\n",
        "scale_images(input_folder, output_folder)\n",
        "print(\"scaling done.\")\n"
      ],
      "metadata": {
        "id": "GFatlVKr3cSN",
        "outputId": "329fc0b4-1792-4d10-9a3b-4f5a43718d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaling done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Your program code here\n",
        "\n",
        "# Perform memory cleanup\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "UPxRLk6tkZDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final splitted dataset"
      ],
      "metadata": {
        "id": "vskLzaqZhrgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/dataset/1080p/\""
      ],
      "metadata": {
        "id": "V7BKpFXck6kT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1080p\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Specify the directory containing the original 1080p images\n",
        "original_dir = '/content/frames/1080p/'\n",
        "\n",
        "# Create a directory to save the cropped images\n",
        "#os.makedirs('path/to/save/cropped/images', exist_ok=True)\n",
        "counter = 1\n",
        "# Iterate over the images in the original directory\n",
        "for filename in os.listdir(original_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "        # Load the original 1080p image\n",
        "        original_path = os.path.join(original_dir, filename)\n",
        "        original_image = cv2.imread(original_path)\n",
        "\n",
        "        # Calculate the dimensions of each cropped part\n",
        "        image_height, image_width, _ = original_image.shape\n",
        "        crop_height = image_height // 3\n",
        "        crop_width = image_width // 3\n",
        "\n",
        "        # Crop the image into 9 equal parts and save them in ascending order\n",
        "\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                start_x = j * crop_width\n",
        "                start_y = i * crop_height\n",
        "                end_x = start_x + crop_width\n",
        "                end_y = start_y + crop_height\n",
        "\n",
        "                cropped_image = original_image[start_y:end_y, start_x:end_x]\n",
        "\n",
        "                # Save the cropped image\n",
        "                save_path = os.path.join('/content/dataset/1080p/', f'{counter:03d}.jpg')\n",
        "                cv2.imwrite(save_path, cropped_image)\n",
        "\n",
        "                counter += 1\n",
        "\n",
        "\n",
        "# Print the size of the cropped image\n",
        "cropped_height, cropped_width, _ = cropped_image.shape\n",
        "print(f\"Cropped Image {counter} ({filename}) size: {cropped_width}x{cropped_height}\")\n",
        "print(counter)\n"
      ],
      "metadata": {
        "id": "i9RC-rvZhunY",
        "outputId": "8061a5ce-1e0d-4969-b56d-9751c4c9fe21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropped Image 451 (012.jpg) size: 640x360\n",
            "451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#360p\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Specify the directory containing the original scaled 360p to 1080p images\n",
        "original_dir = '/content/frames/360p/'\n",
        "\n",
        "# Create a directory to save the cropped images\n",
        "#os.makedirs('path/to/save/cropped/images', exist_ok=True)\n",
        "counter = 1\n",
        "# Iterate over the images in the original directory\n",
        "for filename in os.listdir(original_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "        # Load the original 1080p image\n",
        "        original_path = os.path.join(original_dir, filename)\n",
        "        original_image = cv2.imread(original_path)\n",
        "\n",
        "        # Calculate the dimensions of each cropped part\n",
        "        image_height, image_width, _ = original_image.shape\n",
        "        crop_height = image_height // 3\n",
        "        crop_width = image_width // 3\n",
        "\n",
        "        # Crop the image into 9 equal parts and save them in ascending order\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                start_x = j * crop_width\n",
        "                start_y = i * crop_height\n",
        "                end_x = start_x + crop_width\n",
        "                end_y = start_y + crop_height\n",
        "\n",
        "                cropped_image = original_image[start_y:end_y, start_x:end_x]\n",
        "\n",
        "                # Save the cropped image\n",
        "                save_path = os.path.join('/content/dataset/360s/', f'{filename}')\n",
        "                cv2.imwrite(save_path, cropped_image)\n",
        "\n",
        "                counter += 1\n",
        "\n",
        "# Print the size of the cropped image\n",
        "cropped_height, cropped_width, _ = cropped_image.shape\n",
        "print(f\"Cropped Image {counter} ({filename}) size: {cropped_width}x{cropped_height}\")\n"
      ],
      "metadata": {
        "id": "cVfHdgUAhyLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clearing the ram used"
      ],
      "metadata": {
        "id": "b8DWobEtkLgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Your program code here\n",
        "\n",
        "# Perform memory cleanup\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "IBqALelDkNVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "QvfUC2Vq4F0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "# Step 1: Organize data and directories\n",
        "original_dir = '/content/dataset/1080p/'  # Directory containing original 1080p images\n",
        "scaled_dir = '/content/dataset/360s/'  # Directory containing scaled images\n",
        "\n",
        "# Step 2: Load and preprocess the images\n",
        "original_images = []\n",
        "scaled_images = []\n",
        "\n",
        "for filename in os.listdir(original_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "        original_path = os.path.join(original_dir, filename)\n",
        "        scaled_path = os.path.join(scaled_dir, filename)\n",
        "\n",
        "        original_image = cv2.imread(original_path)\n",
        "        scaled_image = cv2.imread(scaled_path)\n",
        "\n",
        "       # Preprocess the images (resize and normalize)\n",
        "        original_image = original_image / 255.0  # Resize to 1080p\n",
        "        scaled_image = scaled_image / 255.0  # Resize to 1080p\n",
        "\n",
        "        original_images.append(original_image)\n",
        "        scaled_images.append(scaled_image)\n",
        "\n",
        "original_images = np.array(original_images)\n",
        "scaled_images = np.array(scaled_images)\n",
        "\n",
        "# Step 3: Define the U-Net model architecture\n",
        "inputs = Input(shape=(1080, 1920, 3))  # Update input shape\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "\n",
        "up5 = Conv2D(256, 2, activation='relu', padding='same')(up5)\n",
        "merge5 = concatenate([conv3, up5], axis=3)\n",
        "conv5 = Conv2D(256, 3, activation='relu', padding='same')(merge5)\n",
        "conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
        "up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "\n",
        "up6 = Conv2D(128, 2, activation='relu', padding='same')(up6)\n",
        "merge6 = concatenate([conv2, up6], axis=3)\n",
        "conv6 = Conv2D(128, 3, activation='relu', padding='same')(merge6)\n",
        "conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
        "up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "\n",
        "up7 = Conv2D(64, 2, activation='relu', padding='same')(up7)\n",
        "merge7 = concatenate([conv1, up7], axis=3)\n",
        "conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
        "conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "output = Conv2D(3, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Step 4: Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(scaled_images, original_images, batch_size=32, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Step 5: Save the trained model\n",
        "model.save('/content/model.h5')\n",
        "print(\"model done.\")\n",
        "\n",
        "# Perform memory cleanup\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "mak56DIk4Cjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicting"
      ],
      "metadata": {
        "id": "kobakGIDYfs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate the model (optional)\n",
        "#test_images = \"/content/scaled/022.jpg\"  # Load test images\n",
        "#predicted_images = model.predict(test_images)\n",
        "\n",
        "# Step 7: Inference on new scaled images (optional)\n",
        "new_scaled_image = cv2.imread('/content/scaled/022.jpg')\n",
        "new_scaled_image = cv2.resize(new_scaled_image, (1920, 1080)) / 255.0  # Resize to 1080p and normalize\n",
        "predicted_image = model.predict(np.array([new_scaled_image]))\n",
        "predicted_image = predicted_image[0] * 255.0\n",
        "cv2.imwrite('/content/image.jpg', predicted_image)\n",
        "\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "AiabOG5cYfMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating"
      ],
      "metadata": {
        "id": "wEPwSgq6ZwTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage.metrics import mean_squared_error, structural_similarity\n",
        "\n",
        "def compare_images(original_dir, predicted_dir):\n",
        "    mse_total = 0\n",
        "    ssim_total = 0\n",
        "    num_images = 0\n",
        "\n",
        "    for filename in os.listdir(original_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "            original_path = os.path.join(original_dir, filename)\n",
        "            predicted_path = os.path.join(predicted_dir, filename)\n",
        "\n",
        "            original_image = cv2.imread(original_path)\n",
        "            predicted_image = cv2.imread(predicted_path)\n",
        "\n",
        "            original_image = cv2.resize(original_image, (256, 256))\n",
        "            predicted_image = cv2.resize(predicted_image, (256, 256))\n",
        "\n",
        "            mse = mean_squared_error(original_image, predicted_image)\n",
        "            ssim = structural_similarity(original_image, predicted_image, multichannel=True)\n",
        "\n",
        "            mse_total += mse\n",
        "            ssim_total += ssim\n",
        "            num_images += 1\n",
        "\n",
        "    mse_avg = mse_total / num_images\n",
        "    ssim_avg = ssim_total / num_images\n",
        "\n",
        "    accuracy = 1.0 - mse_avg  # Inverse MSE is used as accuracy metric\n",
        "\n",
        "    return accuracy, mse_avg, ssim_avg\n",
        "\n",
        "# Paths to the original and predicted image directories\n",
        "original_dir = '/content/Pre_orginal/'\n",
        "predicted_dir = '/content/predicted/'\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/model.h5')\n",
        "\n",
        "# Make predictions on new images and save them to the predicted directory\n",
        "# new_images = [...]  # Load new images for prediction\n",
        "# for i, image in enumerate(new_images):\n",
        "#     predicted_image = model.predict(np.array([image]))\n",
        "#     predicted_image = np.squeeze(predicted_image) * 255.0\n",
        "#     cv2.imwrite(os.path.join(predicted_dir, f'predicted_{i}.jpg'), predicted_image)\n",
        "\n",
        "# Compare the predicted images with the original images and calculate accuracy\n",
        "accuracy, mse, ssim = compare_images(original_dir, predicted_dir)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"SSIM: {ssim:.4f}\")\n"
      ],
      "metadata": {
        "id": "nwCf_6KmcEoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checkin that cropped image and coresponding region of cropped image in original ti know is there any pixel or quality loss"
      ],
      "metadata": {
        "id": "ZXq_mk1sfCpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O nivetha.jpg \"https://pbs.twimg.com/media/FgiNhi1aAAAm43h?format=jpg&name=large\""
      ],
      "metadata": {
        "id": "x9iR8AJ1ftHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the original image\n",
        "original_image = cv2.imread('/content/nivetha.jpg')\n",
        "\n",
        "# Define the region of interest (ROI) coordinates\n",
        "x = 100  # starting x-coordinate\n",
        "y = 200  # starting y-coordinate\n",
        "width = 300  # width of the ROI\n",
        "height = 200  # height of the ROI\n",
        "\n",
        "# Crop the image based on the ROI\n",
        "cropped_image = original_image[y:y+height, x:x+width]\n",
        "\n",
        "# Compare pixel values of the cropped image with the corresponding region in the original image\n",
        "are_same = np.array_equal(cropped_image, original_image[y:y+height, x:x+width])\n",
        "\n",
        "# Print the result\n",
        "if are_same:\n",
        "    print(\"The pixel values of the cropped image and the corresponding region in the original image are the same.\")\n",
        "else:\n",
        "    print(\"The pixel values of the cropped image and the corresponding region in the original image are different.\")\n"
      ],
      "metadata": {
        "id": "EV4v5mqpffCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}