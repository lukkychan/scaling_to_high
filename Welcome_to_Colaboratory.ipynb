{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukkychan/scaling_to_high/blob/main/Welcome_to_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir original_video\n",
        "!mkdir org_no_sound\n",
        "!mkdir -p frames/1080p\n",
        "!mkdir -p frames/360p\n",
        "!mkdir scaled\n",
        "!mkdir predicted\n",
        "!mkdir Pre_orginal"
      ],
      "metadata": {
        "id": "b9snVJi30Ge1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=eDTEiIC0_rE&pp=ygUSc3B5IHRyYWlsZXIgdGVsdWd1"
      ],
      "metadata": {
        "id": "oSal6RfTJJ8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the videos"
      ],
      "metadata": {
        "id": "vMeI6f4UxaYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://rr3---sn-i5h7lnll.googlevideo.com/videoplayback?expire=1687879195&ei=u6maZMqYFIenx_APuNCAgAk&ip=194.163.187.202&id=o-ANy8zHiI3ElVghZRinnLdLDxfM1qNa6sg7D068ivDPo0&itag=18&source=youtube&requiressl=yes&mh=5x&mm=31%2C26&mn=sn-i5h7lnll%2Csn-5hneknek&ms=au%2Conr&mv=m&mvi=3&pl=24&initcwndbps=1251250&spc=qEK7B0Z6aUmT51Xla9sKfs8V-0MyZCw&vprv=1&svpuc=1&mime=video%2Fmp4&gir=yes&clen=7096879&ratebypass=yes&dur=124.435&lmt=1687436485346821&mt=1687857196&fvip=3&fexp=24007246&c=ANDROID&txp=6319224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt&sig=AOq0QJ8wRQIhALOiNAZ__4kpTWWu2r9G6vmQV989xg59qud5MyEaMaFSAiBJO6pubzb7Ay8Awt3WXmVKOpX88hf0UrBr_fw2MFgbZw%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AG3C_xAwRAIgaYo7cJZRDHi76ZtZK-6a-gJsYI3Ls8AVQO7T5cY5l4QCIGJQR3ShqBgRysRd-D4Ex9PFzBuApeI2W7MgXEg7_jzL&title=SPY%20Trailer%20(Telugu)%20|%20Nikhil%20Siddharth%20|%20Garry%20BH%20|%20Charantej%20Uppalapati%20|%20Ishwarya%20Menon\""
      ],
      "metadata": {
        "id": "z3FW3-UDxYSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the audios"
      ],
      "metadata": {
        "id": "xJVOytvJy301"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "ZZnAZuLUy_kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def remove_audio(input_video_path, output_video_path):\n",
        "    # Load the video clip\n",
        "    video = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Remove the audio\n",
        "    video_without_audio = video.without_audio()\n",
        "\n",
        "    # Save the video without audio\n",
        "    video_without_audio.write_videofile(output_video_path, codec='libx264')\n",
        "\n",
        "    # Close the video clip\n",
        "    video.close()\n",
        "\n",
        "# Specify the paths to the input video and desired output video\n",
        "input_video_path = '/content/original_video/1080p.mp4'\n",
        "output_video_path = '/content/org_no_sound/1080p.mp4'\n",
        "\n",
        "# Call the function to remove audio\n",
        "remove_audio(input_video_path, output_video_path)\n",
        "print(\"done.\")\n"
      ],
      "metadata": {
        "id": "VeEXxSqcKAI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def remove_audio(input_video_path, output_video_path):\n",
        "    # Load the video clip\n",
        "    video = VideoFileClip(input_video_path)\n",
        "\n",
        "    # Remove the audio\n",
        "    video_without_audio = video.without_audio()\n",
        "\n",
        "    # Save the video without audio\n",
        "    video_without_audio.write_videofile(output_video_path, codec='libx264')\n",
        "\n",
        "    # Close the video clip\n",
        "    video.close()\n",
        "\n",
        "# Specify the paths to the input video and desired output video\n",
        "input_video_path = '/content/original_video/360p.mp4'\n",
        "output_video_path = '/content/org_no_sound/360p.mp4'\n",
        "\n",
        "# Call the function to remove audio\n",
        "remove_audio(input_video_path, output_video_path)\n",
        "print(\"done.\")\n"
      ],
      "metadata": {
        "id": "RVdzq5Mmy6u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Frames"
      ],
      "metadata": {
        "id": "wwotNercz_mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the video file\n",
        "video_path = \"/content/org_no_sound/360p.mp4\"\n",
        "\n",
        "# Specify the output folder to save the frames\n",
        "output_folder = \"/content/frames/360p/\"\n",
        "\n",
        "# Specify the maximum number of frames to extract\n",
        "max_frames = 50\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the frame interval to evenly sample the frames\n",
        "frame_interval = max(total_frames // max_frames, 1)\n",
        "\n",
        "# Initialize a counter to keep track of the extracted frames\n",
        "frame_count = 0\n",
        "\n",
        "# Loop through the frames and extract the desired number of frames\n",
        "while frame_count < max_frames:\n",
        "    # Read the current frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image file\n",
        "    frame_path = f\"{output_folder}{frame_count:03d}.jpg\"\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    # Increment the frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Move to the next frame based on the frame interval\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "biGN7KYh0DND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the video file\n",
        "video_path = \"/content/org_no_sound/1080p.mp4\"\n",
        "\n",
        "# Specify the output folder to save the frames\n",
        "output_folder = \"/content/frames/1080p/\"\n",
        "\n",
        "# Specify the maximum number of frames to extract\n",
        "max_frames = 50\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the frame interval to evenly sample the frames\n",
        "frame_interval = max(total_frames // max_frames, 1)\n",
        "\n",
        "# Initialize a counter to keep track of the extracted frames\n",
        "frame_count = 0\n",
        "\n",
        "# Loop through the frames and extract the desired number of frames\n",
        "while frame_count < max_frames:\n",
        "    # Read the current frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image file\n",
        "    frame_path = f\"{output_folder}{frame_count:03d}.jpg\"\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    # Increment the frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Move to the next frame based on the frame interval\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "id": "wxI4cUVpKIbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the images to 1080p"
      ],
      "metadata": {
        "id": "teV6as_L3czN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def scale_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all image files in the input folder\n",
        "    image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Construct the input and output file paths\n",
        "        input_path = os.path.join(input_folder, image_file)\n",
        "        output_path = os.path.join(output_folder, image_file)\n",
        "\n",
        "        # Execute FFmpeg command to scale the image to 1920x1080\n",
        "        command = ['ffmpeg', '-i', input_path, '-vf', 'scale=1920:1080', output_path]\n",
        "        subprocess.call(command)\n",
        "\n",
        "# Specify the paths to the input folder and output folder\n",
        "input_folder = '/content/frames/360p/'\n",
        "output_folder = '/content/scaled/'\n",
        "\n",
        "# Call the function to scale the images\n",
        "scale_images(input_folder, output_folder)\n",
        "print(\"scaling done.\")\n"
      ],
      "metadata": {
        "id": "GFatlVKr3cSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "QvfUC2Vq4F0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "# Step 1: Organize data and directories\n",
        "original_dir = '/content/frames/1080p/'  # Directory containing original 1080p images\n",
        "scaled_dir = '/content/scaled/'  # Directory containing scaled images\n",
        "\n",
        "# Step 2: Load and preprocess the images\n",
        "original_images = []\n",
        "scaled_images = []\n",
        "\n",
        "for filename in os.listdir(original_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "        original_path = os.path.join(original_dir, filename)\n",
        "        scaled_path = os.path.join(scaled_dir, filename)\n",
        "\n",
        "        original_image = cv2.imread(original_path)\n",
        "        scaled_image = cv2.imread(scaled_path)\n",
        "\n",
        "       # Preprocess the images (resize and normalize)\n",
        "        original_image = cv2.resize(original_image, (1920, 1080)) / 255.0  # Resize to 1080p\n",
        "        scaled_image = cv2.resize(scaled_image, (1920, 1080)) / 255.0  # Resize to 1080p\n",
        "\n",
        "        original_images.append(original_image)\n",
        "        scaled_images.append(scaled_image)\n",
        "\n",
        "original_images = np.array(original_images)\n",
        "scaled_images = np.array(scaled_images)\n",
        "\n",
        "# Step 3: Define the U-Net model architecture\n",
        "inputs = Input(shape=(1080, 1920, 3))  # Update input shape\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "\n",
        "up5 = Conv2D(256, 2, activation='relu', padding='same')(up5)\n",
        "merge5 = concatenate([conv3, up5], axis=3)\n",
        "conv5 = Conv2D(256, 3, activation='relu', padding='same')(merge5)\n",
        "conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
        "up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "\n",
        "up6 = Conv2D(128, 2, activation='relu', padding='same')(up6)\n",
        "merge6 = concatenate([conv2, up6], axis=3)\n",
        "conv6 = Conv2D(128, 3, activation='relu', padding='same')(merge6)\n",
        "conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
        "up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "\n",
        "up7 = Conv2D(64, 2, activation='relu', padding='same')(up7)\n",
        "merge7 = concatenate([conv1, up7], axis=3)\n",
        "conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
        "conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "output = Conv2D(3, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Step 4: Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(scaled_images, original_images, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Step 5: Save the trained model\n",
        "model.save('/content/model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mak56DIk4Cjs",
        "outputId": "fc438a62-c419-40f0-a102-82c96846c238"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 279s 68s/step - loss: 0.1824 - val_loss: 0.1428\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 267s 67s/step - loss: 0.1350 - val_loss: 0.0707\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 265s 67s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 266s 67s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 266s 67s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 267s 67s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 267s 67s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 265s 68s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 269s 71s/step - loss: 0.0413 - val_loss: 0.0707\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 266s 67s/step - loss: 0.0413 - val_loss: 0.0707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicting"
      ],
      "metadata": {
        "id": "kobakGIDYfs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate the model (optional)\n",
        "#test_images = \"/content/scaled/022.jpg\"  # Load test images\n",
        "#predicted_images = model.predict(test_images)\n",
        "\n",
        "# Step 7: Inference on new scaled images (optional)\n",
        "new_scaled_image = cv2.imread('/content/scaled/022.jpg')\n",
        "new_scaled_image = cv2.resize(new_scaled_image, (1920, 1080)) / 255.0  # Resize to 1080p and normalize\n",
        "predicted_image = model.predict(np.array([new_scaled_image]))\n",
        "predicted_image = predicted_image[0] * 255.0\n",
        "cv2.imwrite('/content/image.jpg', predicted_image)\n",
        "\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiabOG5cYfMu",
        "outputId": "90d4ea59-fb6c-43b3-aede-879d1d5ab3d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating"
      ],
      "metadata": {
        "id": "wEPwSgq6ZwTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage.metrics import mean_squared_error, structural_similarity\n",
        "\n",
        "def compare_images(original_dir, predicted_dir):\n",
        "    mse_total = 0\n",
        "    ssim_total = 0\n",
        "    num_images = 0\n",
        "\n",
        "    for filename in os.listdir(original_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions if needed\n",
        "            original_path = os.path.join(original_dir, filename)\n",
        "            predicted_path = os.path.join(predicted_dir, filename)\n",
        "\n",
        "            original_image = cv2.imread(original_path)\n",
        "            predicted_image = cv2.imread(predicted_path)\n",
        "\n",
        "            original_image = cv2.resize(original_image, (256, 256))\n",
        "            predicted_image = cv2.resize(predicted_image, (256, 256))\n",
        "\n",
        "            mse = mean_squared_error(original_image, predicted_image)\n",
        "            ssim = structural_similarity(original_image, predicted_image, multichannel=True)\n",
        "\n",
        "            mse_total += mse\n",
        "            ssim_total += ssim\n",
        "            num_images += 1\n",
        "\n",
        "    mse_avg = mse_total / num_images\n",
        "    ssim_avg = ssim_total / num_images\n",
        "\n",
        "    accuracy = 1.0 - mse_avg  # Inverse MSE is used as accuracy metric\n",
        "\n",
        "    return accuracy, mse_avg, ssim_avg\n",
        "\n",
        "# Paths to the original and predicted image directories\n",
        "original_dir = '/content/Pre_orginal/'\n",
        "predicted_dir = '/content/predicted/'\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/model.h5')\n",
        "\n",
        "# Make predictions on new images and save them to the predicted directory\n",
        "# new_images = [...]  # Load new images for prediction\n",
        "# for i, image in enumerate(new_images):\n",
        "#     predicted_image = model.predict(np.array([image]))\n",
        "#     predicted_image = np.squeeze(predicted_image) * 255.0\n",
        "#     cv2.imwrite(os.path.join(predicted_dir, f'predicted_{i}.jpg'), predicted_image)\n",
        "\n",
        "# Compare the predicted images with the original images and calculate accuracy\n",
        "accuracy, mse, ssim = compare_images(original_dir, predicted_dir)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"SSIM: {ssim:.4f}\")\n"
      ],
      "metadata": {
        "id": "nwCf_6KmcEoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}